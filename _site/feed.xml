<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-09-05T17:27:04+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Charlesâ€™ Idea Warehourse</title><subtitle>Ideas come from thinking different.ğŸŒ¿</subtitle><entry><title type="html">Macç³»ç»Ÿä½¿ç”¨jekyllåˆ›å»ºä¸€ä¸ªåšå®¢</title><link href="http://localhost:4000/2023/09/05/use-jekyll-to-build-blog.html" rel="alternate" type="text/html" title="Macç³»ç»Ÿä½¿ç”¨jekyllåˆ›å»ºä¸€ä¸ªåšå®¢" /><published>2023-09-05T10:50:38+08:00</published><updated>2023-09-05T10:50:38+08:00</updated><id>http://localhost:4000/2023/09/05/use-jekyll-to-build-blog</id><content type="html" xml:base="http://localhost:4000/2023/09/05/use-jekyll-to-build-blog.html"><![CDATA[<p>å› ä¸ºhexoç‰ˆæœ¬æ›´æ–°åæ€»æ˜¯æœ‰å„ç§å„æ ·çš„é—®é¢˜ï¼Œæ‰€ä»¥ç»ˆäºå†³å®šæŠŠç°æœ‰çš„åšå®¢æ¢æ‰äº†ï¼Œç›®å‰çš„è®¡åˆ’æ˜¯ä½¿ç”¨jekyll</p>

<h1 id="ä¸‹è½½">ä¸‹è½½</h1>

<p>æ ¹æ®å®˜æ–¹çš„æ•™ç¨‹ï¼Œåœ¨macä¸Šä¸‹è½½jekyllè¿˜æ˜¯æ¯”è¾ƒç®€å•çš„ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  gem install bundler jekyll

  jekyll new my-awesome-site

  cd my-awesome-site

  bundle exec jekyll serve

</code></pre></div></div>

<p>å› ä¸ºmacæœ¬èº«è‡ªå¸¦äº†rubyå’Œgemçš„åŒ…ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥ä½¿ç”¨å¯¹åº”çš„å‘½ä»¤è¡Œ</p>

<p>ä½†æ˜¯æœ¬äººåœ¨å…·ä½“ä½¿ç”¨æ—¶ç›´æ¥æŠ¥é”™ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) chaos@Charles-MacBook-Pro ~ % gem install bundler jekyll
Fetching bundler-2.4.19.gem
ERROR:  While executing gem ... (Gem::FilePermissionError)
    You don't have write permissions for the /Library/Ruby/Gems/2.6.0 directory.
</code></pre></div></div>
<p>æ‡’å¾—è¿›è¡Œé—®é¢˜å®šä½å’Œè§£å†³äº†ï¼Œåé¢ç›´æ¥è‡ªå·±é‡æ–°é…ç½®äº†ä¸€å¥—rubyç¯å¢ƒä½¿ç”¨ï¼Œçœå¾—é‡åˆ°å„ç§æƒé™é—®é¢˜</p>

<h2 id="ä½¿ç”¨è‡ªå·±ä¸‹è½½çš„rubyç¯å¢ƒè¿›è¡Œé…ç½®">ä½¿ç”¨è‡ªå·±ä¸‹è½½çš„rubyç¯å¢ƒè¿›è¡Œé…ç½®</h2>
<p>ä½¿ç”¨homebrewé‡æ–°ä¸‹è½½rubyå¹¶è¿›è¡Œå¯¹åº”é…ç½®ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew install ruby
</code></pre></div></div>
<p>å®‰è£…å®Œæˆåï¼Œ ä¿®æ”¹.bashrcæ–‡ä»¶, ä½¿ç³»ç»Ÿè°ƒç”¨æ—¶ä½¿ç”¨brewä¸‹è½½çš„rubyè€Œä¸æ˜¯ç³»ç»Ÿè‡ªå¸¦çš„æ–‡ä»¶:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>echo 'export PATH="/usr/local/opt/ruby/bin:$PATH"' &gt;&gt; ~/.zshrc
source ~/.zshrc
</code></pre></div></div>
<p>ps: è·¯å¾„éœ€è¦é…ç½®ä¸ºbrewä¸‹è½½çš„rubyçš„binè·¯å¾„ä½ç½®, å¯ä»¥é€šè¿‡</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew list ruby
</code></pre></div></div>

<p>æŸ¥è¯¢rubyä¸‹è½½ä½ç½®</p>

<h3 id="é…ç½®gemè¿è¡Œç¯å¢ƒ">é…ç½®gemè¿è¡Œç¯å¢ƒ</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>echo 'export PATH="$HOME/.gem/ruby/X.X.0/bin:$PATH"' &gt;&gt; ~/.zshrc
source ~/.zshrc
</code></pre></div></div>
<p>é…ç½®å®Œæˆåå°±å¯ä»¥ä½¿ç”¨è‡ªå·±çš„rubyå’Œgemä¸‹è½½jekyll</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem install --user-install bundler jekyll

</code></pre></div></div>

<h2 id="é…ç½®å›½å†…é•œåƒæº">é…ç½®å›½å†…é•œåƒæº</h2>

<p>ç”±äºå›½å†…çš„é˜²ç«å¢™é˜»æ–­äº†å’Œ ruby æœåŠ¡å™¨çš„é“¾æ¥ï¼Œruby çš„èµ„æºæ–‡ä»¶å­˜æ”¾åœ¨ Amazon çš„æœåŠ¡å™¨ä¸Šï¼Œå¥½åƒå¥½å¤šå›½å¤–çš„äº‘ç©ºé—´éƒ½å­˜æ”¾åœ¨ Amazon çš„æœåŠ¡å™¨ä¸Šï¼Œåœ¨ä¸­å›½éƒ½ä¸èƒ½æ­£å¸¸è®¿é—®ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/
$ gem sources -l
https://gems.ruby-china.com
</code></pre></div></div>

<h1 id="åˆ›å»ºä¸€ä¸ªæ–°çš„blog">åˆ›å»ºä¸€ä¸ªæ–°çš„blog</h1>

<p>æ ¹æ®å®˜æ–¹çš„å»ºè®®, åˆ›å»ºä¸€ä¸ªå®ä¾‹:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ jekyll new my-site
$ cd my-site
</code></pre></div></div>

<p>è¿›å…¥ç›®å½•å</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle exec jekyll serve

</code></pre></div></div>
<p>å®Œæˆåå°±å¯ä»¥åœ¨ http://127.0.0.1:4000/ æŸ¥çœ‹jekyllçš„é»˜è®¤ç«™ç‚¹çš„æ ·å­äº†.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[å› ä¸ºhexoç‰ˆæœ¬æ›´æ–°åæ€»æ˜¯æœ‰å„ç§å„æ ·çš„é—®é¢˜ï¼Œæ‰€ä»¥ç»ˆäºå†³å®šæŠŠç°æœ‰çš„åšå®¢æ¢æ‰äº†ï¼Œç›®å‰çš„è®¡åˆ’æ˜¯ä½¿ç”¨jekyll]]></summary></entry><entry><title type="html">ShapePredictor åŸç†åˆ†æ</title><link href="http://localhost:4000/2023/09/01/shapePredictor.html" rel="alternate" type="text/html" title="ShapePredictor åŸç†åˆ†æ" /><published>2023-09-01T22:21:35+08:00</published><updated>2023-09-01T22:21:35+08:00</updated><id>http://localhost:4000/2023/09/01/shapePredictor</id><content type="html" xml:base="http://localhost:4000/2023/09/01/shapePredictor.html"><![CDATA[<h1 id="å‰è¨€">å‰è¨€</h1>

<p>Dlib åº“ä¸­çš„ shape predictor æ˜¯åŸºäºè®ºæ–‡ï¼š One Millisecond Face Alignment with an Ensemble of Regression Trees ä¸­æå‡ºçš„ ERT(Ensemble of Regression Trees) çº§è”å›å½’æ ‘è¿›è¡Œå®ç°çš„, é€šè¿‡è¿›è¡Œç‰¹å¾é€‰æ‹©å¹¶æœ€å°åŒ–æŸå¤±å‡½æ•°.</p>

<p><img src="intro.png" alt="" /></p>

<!-- more -->

<h1 id="çº§è”å›å½’å™¨">çº§è”å›å½’å™¨</h1>

<p>è®°$x_i \in R^2$ ä¸ºå›¾ç‰‡$I$ä¸­çš„ç¬¬ $i$ ä¸ªé¢éƒ¨ç‰¹å¾ç‚¹,åŒ…æ‹¬äº†è¯¥ç‚¹çš„ $(x,y)$ åæ ‡, åŒæ—¶ä½¿ç”¨å‘é‡ $S = (x_1^T, â€¦, x_p^T)^T \in R^{2p}$ ä½œä¸ºå›¾ç‰‡ $I$ ä¸­çš„æ‰€æœ‰ $p$ ä¸ªé¢éƒ¨ç‰¹å¾ç‚¹, $\hat{S}^{(t)}$ ä¸ºå½“å‰å¯¹äº Ground Truth $S$ çš„é¢„æµ‹. çº§è”ä¸­çš„æ¯ä¸€ä¸ªå›å½’å™¨ $r_t( . , . )$ é¢„æµ‹åŸºäºå½“å‰çš„é¢„æµ‹ $\hat{S}^{(t)}$ çš„æ›´æ–°å‘é‡, å¹¶æ·»åŠ åˆ°å½“å‰çš„å½¢çŠ¶é¢„æµ‹å™¨ä¸­æ¥æé«˜é¢„æµ‹ç»“æœ:</p>

\[\hat{S}^{(t+1)} = \hat{S}^{(t)} + r_t(I, \hat{S}^{(t)})\]

<p>å› ä¸º$r_t$çš„é¢„æµ‹æ˜¯åŒæ—¶åŸºäºä¾‹å¦‚åƒç´ å¯†é›†åº¦è¿™ç§ä»å›¾åƒ $I$ ä¸­è®¡ç®—çš„ç‰¹å¾, å¹¶ä¸”æ ¹æ®å½“å‰çš„å›¾åƒé¢„æµ‹å™¨ $\hat{S}^{(t)}$ ä½œä¸ºç´¢å¼•. è¿™æ ·ä¸ºæ•´ä¸ªè¿‡ç¨‹æä¾›äº†å‡ ä½•ä¸å˜æ€§.</p>

<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­, æ¯ä¸€ä¸ªå›å½’å™¨ $r_t$ ä½¿ç”¨æ¢¯åº¦æ ‘æå‡(gradient tree boosting)ä¸è¯¯å·®æŸå¤±å¹³æ–¹å’Œ(sum of square error loss).</p>

<h1 id="è®­ç»ƒçº§è”å›å½’å™¨">è®­ç»ƒçº§è”å›å½’å™¨</h1>

<h2 id="è®­ç»ƒç¬¬ä¸€ä¸ªå›å½’å™¨">è®­ç»ƒç¬¬ä¸€ä¸ªå›å½’å™¨</h2>

<p>ä½¿ç”¨ä¸€ä¸ªä¸‰å…ƒç»„æ¥åˆå§‹åŒ–æœ€åˆçš„å›å½’å‡½æ•°$r_0$, å…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªé¢éƒ¨å›¾ç‰‡, ä¸€ä¸ªåˆå§‹å½¢çŠ¶é¢„æµ‹å’Œä¸€ä¸ªç›®æ ‡æ›´æ–°æ­¥é•¿ $(I_{\pi_i}, \hat{S}_i^{(0)}, \Delta S_i^{(0)})$.</p>

<p>å…¶ä¸­:</p>

\[\pi_i \in \{1, ..., n\} \\\]

\[\hat{S}_i^{(0)} \in \lbrace S_1, ..., S_n \rbrace \not  S_{\pi_i}\\\]

\[\Delta S_i^{(0)} = S_{\pi_i} - \hat{S}_i^{(0)}\]

<p>ä¸‰å…ƒç»„çš„æ€»æ•°ä¸º $N = nR$, $R$ ä¸ºç”¨äºæ¯ä¸€å¼ ç…§ç‰‡çš„åˆå§‹åŒ–æ•°é‡. æ¯ä¸€ä¸ªåˆå§‹åŒ–çš„å½¢çŠ¶é¢„æµ‹å™¨ä»${ S_1, â€¦, S_n}$ ä¸­å‡åŒ€é‡‡æ ·.</p>

<h2 id="å•å›å½’å™¨å†…çš„æ¢¯åº¦æå‡æ ‘è®­ç»ƒ">å•å›å½’å™¨å†…çš„æ¢¯åº¦æå‡æ ‘è®­ç»ƒ</h2>

<p>è¾“å…¥: ä¸‰å…ƒç»„</p>

\[\{(I_{\pi_i}, \hat{S}_i^{(t)}, \Delta S_i^{(t)})\}_{i=1}^N\]

<p>å’Œæ”¶ç¼©å› æ•°$0 &lt; \gamma &lt; 1$</p>

<p>åˆå§‹åŒ–:</p>

\[f_0(I, \hat{S}^{(t)}) = {argmin}_{\gamma \in R^{2p}} \sum_{i=1}^N || \Delta S_i^{(t)} - \gamma||^2\]

<p>å¯¹äºå›å½’å™¨ä¸­çš„æ¢¯åº¦æå‡æ ‘ k = 1, â€¦, K:</p>
<ol>
  <li>ä»¤ $i = 1, .., N$</li>
</ol>

\[r_{ik} =  \Delta S_i^{(t)} - f_{k-1}(I_{\pi_i}, \hat{S}_i^{(t)})\]

<ol>
  <li>ä½¿ç”¨ä¸€ä¸ªå›å½’æ ‘$g_k(I, \hat{S}<em>i^{(t)})$ å¯¹ç›®æ ‡ $r</em>{ik}$ è¿›è¡Œæ‹Ÿåˆ</li>
  <li>æ›´æ–°$f$</li>
</ol>

\[f_k(I, \hat{S}^{(t)}) = f_{k-1}(I, \hat{S}^{(t)}) + \gamma g_k(I, \hat{S}^{(t)})\]

<p>è¾“å‡º $r_t(I, \hat{S}^{(t)}) = f_K(I, \hat{S}^{(t)})$</p>

<h2 id="å›å½’å™¨çº§è”è®­ç»ƒ">å›å½’å™¨çº§è”è®­ç»ƒ</h2>

<p>é€šè¿‡ä¸Šé¢çš„ç®—æ³•æˆ‘ä»¬å¯ä»¥å¾—åˆ°å›å½’é¢„æµ‹å™¨$r_0$, åŒæ—¶ç”¨äºè®­ç»ƒçš„åˆå§‹ä¸‰å…ƒç»„é€šè¿‡è®¾å®š:</p>

\[\hat{S}_i^{(t+1)} = \hat{S}_i^{(t)} + r_t(I, \hat{S}^{(t)}) \\
\Delta S_i^{(t+1)} = S_{\pi_i} - S_i^{(t+1)}\]

<p>è¢«æ›´æ–°ä¸ºäº†$(I_{\pi_i}, \hat{S}_i^{(1)}, \Delta S_i^{(1)})$, å¯¹äºä¸‹ä¸€ä¸ªå›å½’å™¨ $r_1$,</p>

<h2 id="å›å½’æ ‘è®­ç»ƒç»†èŠ‚">å›å½’æ ‘è®­ç»ƒç»†èŠ‚</h2>

<p>åœ¨å›å½’å™¨çš„è®­ç»ƒè¿‡ç¨‹ä¸­, å…³é”®ç‚¹åœ¨äºæ¯ä¸ªå›å½’å™¨å†…çš„æ¢¯åº¦æå‡æ ‘å¯¹æ®‹å·®ç›®æ ‡çš„æ‹Ÿåˆæ•ˆæœ. åœ¨æ–‡ä¸­å…±æå‡ºäº†ä¸‰ä¸ªæ–¹é¢:</p>

<ul>
  <li>å½¢çŠ¶æ— å…³çš„åˆ’åˆ†æµ‹è¯•</li>
  <li>é€‰æ‹©èŠ‚ç‚¹åˆ’åˆ†</li>
  <li>ç‰¹å¾é€‰æ‹©</li>
</ul>

<p>å…·ä½“ç»†èŠ‚å¯ä»¥çœ‹åŸè®ºæ–‡.</p>

<p><img src="image.png" alt="" /></p>

<h1 id="ç»“è¯­">ç»“è¯­</h1>

<p>è¯¥ç®—æ³•ç»™dlibåº“ä¸­çš„shape predictoræä¾›äº†ç†è®ºåŸºç¡€, å¹¶ä¸”åœ¨dlibä¸­æœ€ç»ˆé€‰æ‹©ä½¿ç”¨68ä¸ªlandmarkæ¥è®©ä¸Šæ–‡çš„çº§è”å›å½’æ ‘è¿›è¡Œæ‹Ÿåˆ, åœ¨åŸæ–‡ä¸­ä¹Ÿæµ‹è¯•äº†400, 200, 80, 40, 20 ç­‰ä¸åŒæ•°é‡çš„åˆå§‹å½¢çŠ¶æ•°é‡.</p>

<p><img src="conclu.png" alt="" /></p>]]></content><author><name></name></author><summary type="html"><![CDATA[å‰è¨€]]></summary></entry><entry><title type="html">äººè„¸è¯†åˆ«é¡¹ç›®å®æˆ˜ç¬”è®°</title><link href="http://localhost:4000/2023/07/07/face-recognition-notes.html" rel="alternate" type="text/html" title="äººè„¸è¯†åˆ«é¡¹ç›®å®æˆ˜ç¬”è®°" /><published>2023-07-07T21:47:27+08:00</published><updated>2023-07-07T21:47:27+08:00</updated><id>http://localhost:4000/2023/07/07/face-recognition-notes</id><content type="html" xml:base="http://localhost:4000/2023/07/07/face-recognition-notes.html"><![CDATA[<h1 id="å‰è¨€">å‰è¨€</h1>

<p>äººè„¸è¯†åˆ«çš„ä¸»è¦æµç¨‹åŒ…æ‹¬äº†: äººè„¸æ£€æµ‹, äººè„¸å½’ä¸€åŒ–, äººè„¸ä¿¡æ¯ç¼–ç  å¤§è‡´çš„ä¸‰ä¸ªæµç¨‹. å…¶ä¸­äººè„¸æ£€æµ‹å’Œäººè„¸ä¿¡æ¯ç¼–ç è¿™ä¸¤ä¸ªéƒ¨åˆ†å¯ä»¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œæ•°æ®çš„å¤„ç†ä»¥è¾¾åˆ°æ›´å¥½çš„æ•ˆæœ.</p>

<p>é™¤äº†ä»æ¨¡å‹æ¡†æ¶å¼€å§‹æ‰‹æ“æ•´ä½“çš„æ¡†æ¶ä¹‹å¤–, ç°æœ‰ä¸€äº›å³æ’å³ç”¨çš„äººè„¸è¯†åˆ«æ¡†æ¶ä¹Ÿèƒ½å¤Ÿæ»¡è¶³é¡¹ç›®éƒ¨ç½²çš„å®é™…ä½¿ç”¨, å¦‚ <code class="language-plaintext highlighter-rouge">deepface</code>, <code class="language-plaintext highlighter-rouge">dlib</code>, <code class="language-plaintext highlighter-rouge">opencv</code> ç­‰. åœ¨æœ¬ç¯‡åšå®¢ä¸­å°†åˆ†åˆ«ä»‹ç»ç”±è‡ªå·±æ„å»ºçš„ä¸€å¥—äººè„¸è¯†åˆ«æ¡†æ¶, ä»¥åŠä½¿ç”¨ <code class="language-plaintext highlighter-rouge">dlib</code> è¿›è¡Œå¼€å‘çš„æµç¨‹</p>

<h1 id="åŸºäº-facenet-å’Œ-retinaface-å¼€å‘çš„æ¡†æ¶">åŸºäº FaceNet å’Œ RetinaFace å¼€å‘çš„æ¡†æ¶</h1>

<p>å¯¹äºäººè„¸è¯†åˆ«çš„é¡¹ç›®æ¥è¯´, æˆ‘ä»¬æœ‰ä¸€ä¸ªå­˜æœ‰äººå‘˜é¢éƒ¨ç…§ç‰‡çš„æ•°æ®åº“ (èº«ä»½è¯è¯ä»¶ç…§), å½“ç›¸æœºæ•æ‰åˆ°æ–°çš„äººè„¸æ—¶, æˆ‘ä»¬éœ€è¦ä¸æ•°æ®åº“ä¸­çš„ç…§ç‰‡è¿›è¡Œæ¯”è¾ƒ. åˆ¤æ–­äººå‘˜çš„èº«ä»½.</p>

<h2 id="äººè„¸ä¿¡æ¯æ³¨å†Œ">äººè„¸ä¿¡æ¯æ³¨å†Œ</h2>

<p>æˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»ºäººè„¸æ•°æ®ä¿¡æ¯çš„gallery, å¤§è‡´çš„é€»è¾‘å¦‚ä¸‹</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>å¯¹äºæ•°æ®åº“ä¸­çš„æ¯å¼ ç…§ç‰‡, æ‰§è¡Œäººè„¸æ£€æµ‹, äººè„¸ä¿¡æ¯ç¼–ç æ“ä½œ
å°†ä¿å­˜çš„äººè„¸ä¿¡æ¯å­˜å…¥æ–‡ä»¶ä¸­, ä»¥å¾…æœªæ¥çš„ä½¿ç”¨
</code></pre></div></div>

<p>åœ¨é¡¹ç›®ä¸­, æˆ‘ä»¬å…ˆä½¿ç”¨ <code class="language-plaintext highlighter-rouge">Facenet</code> è¿›è¡Œç›®æ ‡çš„è¯†åˆ«</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mtcnn</span> <span class="o">=</span> <span class="nc">MTCNN</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="mi">160</span><span class="p">,</span> 
              <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
              <span class="n">min_face_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> 
              <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
              <span class="p">)</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="nc">InceptionResnetV1</span><span class="p">(</span><span class="n">classify</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                            <span class="n">pretrained</span><span class="o">=</span><span class="sh">'</span><span class="s">vggface2</span><span class="sh">'</span><span class="p">,</span>
                            <span class="n">num_classes</span><span class="o">=</span><span class="mi">0</span>
                           <span class="p">).</span><span class="nf">eval</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

</code></pre></div></div>

<p>åœ¨å®æ“ä¸­, <code class="language-plaintext highlighter-rouge">mtcnn</code> å’Œ <code class="language-plaintext highlighter-rouge">resnet</code> åˆ†åˆ«ç”¨äºäººè„¸æ£€æµ‹å’Œä¿¡æ¯ç¼–ç .</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_faces</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">))</span>
    <span class="n">img_face</span> <span class="o">=</span> <span class="nf">mtcnn</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

    <span class="n">img_embedding</span> <span class="o">=</span> <span class="nf">resnet</span><span class="p">(</span><span class="n">img_face</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">img_embedding</span><span class="p">,</span> <span class="n">file_name</span>

</code></pre></div></div>

<p>å¯¹äºå•å¼ å›¾ç‰‡, æˆ‘ä»¬é¦–å…ˆä½¿ç”¨<code class="language-plaintext highlighter-rouge">mtcnn</code>è¿›è¡Œäººè„¸ä½ç½®çš„æ£€æµ‹, ä¹‹åæˆ‘ä»¬ä½¿ç”¨<code class="language-plaintext highlighter-rouge">resnet</code>æå–512Dçš„äººè„¸ç¼–ç ä¿¡æ¯.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">person_names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">face_embeddings</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">folders</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="k">for</span> <span class="n">folder</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">folders</span><span class="p">):</span>
    <span class="n">new_path</span> <span class="o">=</span> <span class="n">path</span><span class="o">+</span><span class="sh">'</span><span class="s">/</span><span class="sh">'</span><span class="o">+</span><span class="n">folder</span><span class="o">+</span><span class="sh">'</span><span class="s">/</span><span class="sh">'</span>
    <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">new_path</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="k">if</span> <span class="nf">valid_extension</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">img_embedding</span><span class="p">,</span> <span class="n">person_name</span> <span class="o">=</span> <span class="nf">detect_faces</span><span class="p">(</span><span class="n">new_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
                <span class="n">person_names</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">person_name</span><span class="p">)</span>
                <span class="n">face_embeddings</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">img_embedding</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Registering {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">person_name</span><span class="p">))</span>
            <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Error occured during process</span><span class="sh">"</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
                <span class="nf">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="c1"># store known info
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">registry.pkl</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">person_names</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">face_embeddings</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<p>æœ€ç»ˆæˆ‘ä»¬éå†æ•°æ®åº“ä¸­çš„æ¯ä¸€ä¸ªç…§ç‰‡, å®Œæˆä¿¡æ¯çš„ç™»è®°æµç¨‹</p>

<h2 id="æ–°ç…§ç‰‡äººè„¸è¯†åˆ«">æ–°ç…§ç‰‡äººè„¸è¯†åˆ«</h2>

<p>å½“ç›¸æœºæ‹æ‘„åˆ°æ–°çš„äººè„¸æ—¶, æˆ‘ä»¬åªéœ€è¦è¿›è¡Œä¸äººè„¸æ³¨å†Œæ—¶ç›¸åŒçš„äººè„¸æ£€æµ‹æ¨¡å‹çš„æµç¨‹, ä¾¿èƒ½å¤Ÿå¾—åˆ°ç±»ä¼¼çš„äººè„¸ä¿¡æ¯ç¼–ç </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">facenet_recognition</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>

    <span class="k">global</span> <span class="n">face_embeddings</span><span class="p">,</span> <span class="n">person_names</span>
    <span class="k">if</span> <span class="bp">False</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
        <span class="n">img_face</span> <span class="o">=</span> <span class="nf">mtcnn</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">img_embedding</span> <span class="o">=</span> <span class="nf">resnet</span><span class="p">(</span><span class="n">img_face</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">img_embedding</span> <span class="o">=</span> <span class="nf">detect_faces_retinaface</span><span class="p">(</span><span class="n">image_path</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="nf">distance</span><span class="p">(</span><span class="n">img_embedding</span><span class="p">,</span> <span class="n">ref_embedding</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref_embedding</span> <span class="ow">in</span> <span class="n">face_embeddings</span><span class="p">]</span>
    <span class="n">distances_names</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span><span class="o">*</span><span class="nf">sorted</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">person_names</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">distances_names</span>
</code></pre></div></div>

<p>å…¶ä¸­, æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Euclidean Distance (L2) æ¥æ¯”è¾ƒä¸åŒäººè„¸ç¼–ç ä¹‹é—´çš„è·ç¦», æ¥ä½œä¸ºæ¯”è¾ƒä¸åŒäººè„¸ç¼–ç çš„å·®å¼‚:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="n">embeddings1</span><span class="p">,</span> <span class="n">embeddings2</span><span class="p">,</span> <span class="n">distance_metric</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="c1"># Euclidian distance
</span>        <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">embeddings1</span><span class="p">,</span> <span class="n">embeddings2</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">diff</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span>

</code></pre></div></div>

<h1 id="åŸºäº-dlib-å®ç°çš„äººè„¸è¯†åˆ«æ¡†æ¶">åŸºäº <code class="language-plaintext highlighter-rouge">Dlib</code> å®ç°çš„äººè„¸è¯†åˆ«æ¡†æ¶</h1>

<p>TBC</p>]]></content><author><name></name></author><summary type="html"><![CDATA[å‰è¨€]]></summary></entry><entry><title type="html">Terraform åŸºç¡€ä½¿ç”¨æ–¹æ³•ä¸ç‰¹æ€§</title><link href="http://localhost:4000/2023/04/06/Terraform.html" rel="alternate" type="text/html" title="Terraform åŸºç¡€ä½¿ç”¨æ–¹æ³•ä¸ç‰¹æ€§" /><published>2023-04-06T16:37:31+08:00</published><updated>2023-04-06T16:37:31+08:00</updated><id>http://localhost:4000/2023/04/06/Terraform</id><content type="html" xml:base="http://localhost:4000/2023/04/06/Terraform.html"><![CDATA[<h1 id="general">General</h1>

<h2 id="1-æ˜¯ä»€ä¹ˆ-what-is-terraform">1. æ˜¯ä»€ä¹ˆ What is Terraform?</h2>

<ul>
  <li>ç”¨äºåŸºç¡€è®¾æ–½ç½®å¤‡ Infrastructure Provisioning</li>
</ul>

<blockquote>
  <p>ä»€ä¹ˆæ˜¯<strong>åŸºç¡€è®¾æ–½ç½®å¤‡</strong>?
åœ¨æˆ‘ä»¬éœ€è¦å°†å·¥ç¨‹/ç³»ç»Ÿéƒ¨ç½²åˆ°äº‘ç«¯æ—¶, æˆ‘ä»¬é€šå¸¸éœ€è¦å‡†å¤‡å¯¹åº”çš„åŸºç¡€è®¾æ–½, ä»¥ AWS ä¸ºä¾‹, æˆ‘ä»¬éœ€è¦å‡†å¤‡ç§æœ‰ç½‘ç»œç©ºé—´ Private network space, EC2æœåŠ¡å™¨å®ä¾‹ server instances, é…ç½®å®‰å…¨ç»„ Security, ä»¥åŠä¸‹è½½å…¶ä»–å·¥å…·æ¡†æ¶(å¦‚ Docker). è¿™ä¸€ç³»åˆ—åˆ›å»ºä¸å‡†å¤‡å·¥ä½œä¸€èˆ¬è®¤ä¸ºæ˜¯åŸºç¡€è®¾æ–½ç½®å¤‡ Infrastructure Provisioning.</p>
</blockquote>

<!-- more -->

<h2 id="ansible-å’Œ-terraform-çš„åŒºåˆ«">Ansible å’Œ Terraform çš„åŒºåˆ«?</h2>

<p>Difference between Ansible and Terraform?</p>

<p>åœ¨å®˜æ–¹æ–‡æ¡£ä¸­, Terraformçš„æè¿°ä¸Ansibleå¾ˆç›¸ä¼¼</p>

<blockquote>
  <p><strong>Terraform</strong>: Terraform Cloud enables infrastructure automation for provisioning, compliance, and management of any cloud, datacenter, and service.</p>

  <p><strong>Ansible</strong>: Ansible is a suite of software tools that enables infrastructure as code. It is open-source and the suite includes software provisioning, configuration management, and application deployment functionality.</p>
</blockquote>

<p>ç›¸åŒç‚¹:</p>

<ul>
  <li>
    <p>åŒæ ·æ˜¯IaaC(Infrastrucutre as a Code)</p>
  </li>
  <li>
    <p>éƒ½è‡ªåŠ¨åŒ–äº†åŸºç¡€è®¾æ–½çš„ç½®å¤‡, é…ç½®, ä»¥åŠç®¡ç†</p>
  </li>
</ul>

<p>ä¸åŒç‚¹:</p>

<ul>
  <li>Terraform ä¸»è¦æ˜¯åŸºç¡€è®¾æ–½ç½®å¤‡å·¥å…·, åŒæ—¶å¯ä»¥ç”¨äºéƒ¨ç½²ç¨‹åº</li>
  <li>Ansible ä¸»è¦æ˜¯é…ç½®ç®¡ç†å·¥å…·, è¿™æ„å‘³ç€Ansibleæ›´å¤šå€¾å‘äºç®¡ç†<strong>å·²ç»ç½®å¤‡å®Œæˆ</strong>çš„åŸºç¡€è®¾æ–½, å¹¶å¯¹å…¶è¿›è¡Œé…ç½®, éƒ¨ç½², æ›´æ–°è½¯ä»¶ç­‰</li>
</ul>

<p>åŸºäºä¸Šé¢ä¸¤ä¸ªå·¥å…·çš„åŒºåˆ«, æˆ‘ä»¬é€šå¸¸å¯ä»¥åŒæ—¶ä½¿ç”¨ä¸¤è€…, ä½¿ç”¨Terraformè¿›è¡ŒåŸºç¡€è®¾æ–½ç½®å¤‡, å¹¶ä½¿ç”¨Ansibleè¿›è¡Œé…ç½®ç®¡ç†</p>

<h2 id="å·¥å…·ç‰¹ç‚¹-characteristics">å·¥å…·ç‰¹ç‚¹ Characteristics</h2>

<ul>
  <li>å¼€æº Open Source</li>
  <li>å£°æ˜å¼ Declarative</li>
</ul>

<blockquote>
  <p>ä»€ä¹ˆæ˜¯ Declarative è¯­å¥?
åœ¨é…ç½®æ–‡ä»¶ä¸­, ä½ åªéœ€è¦å®šä¹‰æœ€ç»ˆçŠ¶æ€ (end state) â€“ <strong>What</strong></p>

  <p>æ¯”å¦‚è¯´, ä½ å¯ä»¥å£°æ˜, éœ€è¦5å°æœ‰ç‰¹å®šé…ç½®çš„æœåŠ¡å™¨; æ‹¥æœ‰ç‰¹å®šæƒé™çš„ AWS user</p>

  <p>ç›¸å¯¹çš„å‘½ä»¤å¼ Imperative è¯­å¥å®šä¹‰äº†å…·ä½“çš„æ¯ä¸€æ­¥åº”è¯¥å¦‚ä½•æ‰§è¡Œ â€“ <strong>How</strong></p>

  <p>Declarative è¯­å¥åœ¨æ›´æ–°åŸºç¡€è®¾æ–½æ—¶æ›´åŠ ç®€å•</p>

  <p>Imperative: ç§»é™¤ä¸¤ä¸ªæœåŠ¡å™¨, æ·»åŠ é˜²ç«å¢™é…ç½®, å¢åŠ  AWS user æƒé™ â€“ ç”±ç®¡ç†å‘˜ç»™å‡ºæŒ‡ç¤º</p>

  <p>Declarative: ç°åœ¨æˆ‘ä»¬æœ‰n-2ä¸ªæœåŠ¡å™¨, ä½¿ç”¨è¿™ä¸ªé˜²ç«å¢™é…ç½®, AWS user æœ‰å¦‚ä¸‹çš„æƒé™ â€“ ç”±å·¥å…·è‡ªå·±ç¡®å®šå“ªäº›éœ€è¦å®Œæˆ</p>
</blockquote>

<h2 id="ä½¿ç”¨åœºæ™¯">ä½¿ç”¨åœºæ™¯</h2>

<ul>
  <li>ç®¡ç†ç°æœ‰åŸºç¡€è®¾æ–½
    <ul>
      <li>åˆ›å»º</li>
      <li>ä¿®æ”¹</li>
    </ul>
  </li>
  <li>å¤åˆ¶åŸºç¡€è®¾æ–½</li>
</ul>

<h2 id="terraform-æ¶æ„">Terraform æ¶æ„</h2>

<h3 id="core">Core</h3>

<p>è¾“å…¥:</p>

<p>TF-config: ç”¨æˆ·é…ç½®çš„è®¾ç½® (ç›®æ ‡é…ç½®)</p>

<p>State: å½“å‰é˜¶æ®µçš„è®¾ç½® (å½“å‰é…ç½®)</p>

<p>ä½œç”¨:</p>

<p>Coreé€šè¿‡æ¯”è¾ƒä¸¤ä¸ªè¾“å…¥, ä½œå‡ºæ‰§è¡Œè®¡åˆ’: å“ªäº›éœ€è¦åˆ›å»º/æ›´æ–°/é”€æ¯?</p>

<h3 id="æœåŠ¡æä¾›è€…-providers">æœåŠ¡æä¾›è€… Providers</h3>

<p>IaaS: AWS / Azure</p>

<p>PaaS: Kubernetes</p>

<p>SaaS: Fastly</p>

<p>é€šè¿‡å¯¹åº”çš„ Provider å®ŒæˆåŸºç¡€è®¾æ–½é…ç½®</p>

<h1 id="åŸºç¡€å‘½ä»¤">åŸºç¡€å‘½ä»¤</h1>

<p><strong>refresh</strong></p>

<p>è¯¢é—®åŸºç¡€è®¾æ–½æä¾›è€…è·å–å½“å‰ State</p>

<p><strong>plan</strong></p>

<p>åˆ›å»ºæ‰§è¡Œè®¡åˆ’</p>

<p>å†³å®šéœ€è¦æ‰§è¡Œå“ªäº›åŠ¨ä½œæ¥åˆ°è¾¾ç›®æ ‡ State</p>

<p><strong>apply</strong></p>

<p>æ‰§è¡Œ plan ä¸­åˆ›å»ºçš„è®¡åˆ’</p>

<p><strong>destroy</strong></p>

<p>æ‘§æ¯èµ„æº/åŸºç¡€è®¾æ–½</p>

<h1 id="å®è·µ">å®è·µ</h1>

<ol>
  <li>ä¸‹è½½</li>
</ol>

<ul>
  <li>MacOS</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; brew install terraform
# ä½¿ç”¨ homebrew ä¸‹è½½
&gt; terraform -v
# æŸ¥çœ‹ç‰ˆæœ¬å·, ç¡®è®¤å®‰è£…æˆåŠŸ
</code></pre></div></div>

<ul>
  <li>Win</li>
  <li>Linux</li>
</ul>

<p>åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶</p>

<p>å€’å…¥æœåŠ¡ provider åŠå…¶ä¸€äº›åŸºç¡€å˜é‡</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>provider â€œaws" {
    region = "us-east-1"
} 
</code></pre></div></div>

<h2 id="åˆ›å»ºèµ„æº">åˆ›å»ºèµ„æº</h2>

<p>åŸºæœ¬è¯­æ³•</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>resources "&lt;provider&gt;_&lt;services&gt;" "name" {

    param1 = ""
    param2 = â€œâ€
}

</code></pre></div></div>

<p>terraform å‘½ä»¤</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;terrafrom init

Initializing the backend...

Initializing provider plugins...

</code></pre></div></div>
<p>ç”¨äºåˆå§‹åŒ–terraformåç«¯, ä¸‹è½½å¯¹åº”çš„provider æ’ä»¶</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&gt; terraform plan 
......

Plan: 1 to add, 0 to change, 0 to destroy.

</code></pre></div></div>

<p>è§„åˆ’, æ£€æŸ¥è¯­å¥, è§„åˆ’å¯¹åº”æ›´æ–°</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;terraform apply
...

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
</code></pre></div></div>

<p>å…·ä½“æ‰§è¡Œä»£ç </p>

<h2 id="ä¿®æ”¹èµ„æº">ä¿®æ”¹èµ„æº</h2>

<p>å½“æˆ‘ä»¬æ‰§è¡Œå®Œæˆå, å¦‚æœæˆ‘ä»¬å†æ‰§è¡Œä¸€æ¬¡ apply, ä¼šæ˜¯ä»€ä¹ˆç»“æœ?</p>

<p>å› ä¸ºterraformä½¿ç”¨declarativeè¯­è¨€, configæ–‡ä»¶ä¸­å®šä¹‰çš„æ˜¯åŸºç¡€è®¾æ–½çš„æœ€ç»ˆçŠ¶æ€, ä¹Ÿå°±æ˜¯è¯´, å¦‚æœä½¿ç”¨ç›®å‰çš„config, ä¸è®ºæˆ‘ä»¬æ‰§è¡Œå¤šå°‘æ¬¡ apply, åœ¨AWSä¸­éƒ½åªä¼šå­˜åœ¨ä¸€ä¸ªinstance</p>

<h2 id="åˆ é™¤èµ„æº">åˆ é™¤èµ„æº</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;terrafrom destroy

</code></pre></div></div>
<p>åˆ é™¤æ‰€æœ‰åŸºç¡€è®¾æ–½</p>

<h2 id="å¼•ç”¨èµ„æº">å¼•ç”¨èµ„æº</h2>

<p>æ¥ä¸‹æ¥å°è¯•åœ¨AWSä¸­åˆ›å»ºä¸€ä¸ªsubnet.</p>

<p>åœ¨AWSä¸­subnetéœ€è¦åœ¨VPCä¸­è¿›è¡Œåˆ›å»º, ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬éœ€è¦å¯¹åˆ›å»ºçš„VPCè¿›è¡Œå¼•ç”¨</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>resource "aws_vpc" "first-vpc" {
    cidr_block = "10.0.0.0/16"
    tags = {
      "Name" = "production"
    }
}

resource "aws_subnet" "subnet-1" {
    vpc_id = aws_vpc.first-vpc.id
    cidr_block = "10.0.1.0/24"
    tags = {
      "Name" = "prod-subnet"
    }
  
}

</code></pre></div></div>

<p>åœ¨è¿™é‡Œ æˆ‘ä»¬ä½¿ç”¨<code class="language-plaintext highlighter-rouge">vpc_id = aws_vpc.first-vpc.id</code>å¯¹vpcçš„idè¿›è¡Œå¼•ç”¨</p>

<ul>
  <li>åœ¨è¿™é‡Œ, ä¸¤ä¸ªresourcesçš„èµ„æºå®šä¹‰é¡ºåº<strong>ä¸ä¼š</strong>å½±å“å¼•ç”¨çš„æ•ˆæœ, terraformä¼šè‡ªåŠ¨ç¡®å®šèµ„æºä¹‹é—´çš„ä¾èµ–å…³ç³»</li>
</ul>

<h2 id="terraform-ç›¸å…³æ–‡ä»¶">Terraform ç›¸å…³æ–‡ä»¶</h2>

<ul>
  <li>.terraformæ–‡ä»¶å¤¹</li>
</ul>

<p>åœ¨ä½¿ç”¨init, plan, deployç­‰ç›¸å…³å‘½ä»¤ä¸­, ä¼šæœ‰ç›¸å…³æ–‡ä»¶è¢«è‡ªåŠ¨åŠ è½½åœ¨ .terraform æ–‡ä»¶å¤¹ä¸­ (ç±»ä¼¼.git)</p>

<ul>
  <li>terraform.tfstate</li>
</ul>

<p>å­˜å‚¨äº†å½“å‰çš„configå®šä¹‰çš„stateçŠ¶æ€</p>

<h2 id="other-commands">Other Commands</h2>

<ul>
  <li>terraform state list</li>
</ul>

<p>å±•ç° terraform ä¸­æ‰€æœ‰çš„ resources</p>

<ul>
  <li>terraform state show &lt;name of resource&gt;</li>
</ul>

<p>å±•ç°æŸä¸ªå…·ä½“ resource çš„ç»†èŠ‚</p>

<p>å¦‚æœæˆ‘ä»¬æƒ³è¦åœ¨<code class="language-plaintext highlighter-rouge">terraform apply</code>å®Œæˆåè‡ªåŠ¨printå¯¹åº”çš„èµ„æºç»†èŠ‚, åœ¨tfæ–‡ä»¶ä¸­æ·»åŠ å¯¹åº”çš„output</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output "server_public_ip" {
  value = aws_eip.one.public_ip
}

</code></pre></div></div>

<p>ä¹‹åå½“æ‰§è¡Œ<code class="language-plaintext highlighter-rouge">terraform apply</code> æ—¶, åœ¨å‘½ä»¤è¡Œä¸­å°±å¯ä»¥è‡ªåŠ¨æ‰“å°å¯¹åº”çš„ä¿¡æ¯</p>

<p>åœ¨æ–‡ä»¶ä¸­å®šä¹‰ä¹‹å, å¯ä»¥ä½¿ç”¨ <code class="language-plaintext highlighter-rouge">terraform output</code> ç›´æ¥æŸ¥çœ‹éƒ¨ç½²æ—¶è·å¾—çš„output. åŒæ—¶, æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡<code class="language-plaintext highlighter-rouge">terraform refresh</code> åˆ·æ–°å¯¹åº”outputçš„çŠ¶æ€</p>

<ul>
  <li>å®šä½resource</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; terraform destroy -target aws_instance.web-server-instance

</code></pre></div></div>

<p>é€šè¿‡å®šä¹‰ <code class="language-plaintext highlighter-rouge">-target</code> æ——å¸œæ¥å…·ä½“çš„åˆ é™¤æŸä¸ªèµ„æº</p>

<p>åŒæ ·çš„, æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨<code class="language-plaintext highlighter-rouge">terraform apply</code> æ—¶å®šä¹‰<code class="language-plaintext highlighter-rouge">-target</code>æ¥å…·ä½“çš„å¯åŠ¨æŸä¸€ä¸ªèµ„æº</p>

<h2 id="variables">Variables</h2>

<p>terraform æ”¯æŒå®šä¹‰å˜é‡variablesæ¥æ˜¯æˆ‘ä»¬å¯¹äºæŸäº›å˜é‡çš„å®šä¹‰</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>variable "subnet_prefix" {
    description = â€œcidr block for the subnetâ€
    # default 
    type = string
}
</code></pre></div></div>
<p>ä¸€ä¸ªå˜é‡æœ‰å¦‚ä¸Šä¸‰ä¸ªå¯é€‰å±æ€§</p>

<h3 id="å¼•ç”¨å˜é‡">å¼•ç”¨å˜é‡</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>resource "aws_subne" "subnet-1" {
  vpc_id = aws_vpc.prod-vpc.id
  cidr_block = var.subnet_prefix
  ...
}

</code></pre></div></div>

<p>ä¸Šé¢æˆ‘ä»¬ä½¿ç”¨<code class="language-plaintext highlighter-rouge">var.subnet_prefix</code>å®šä¹‰äº†<code class="language-plaintext highlighter-rouge">cidr_block</code>çš„å†…å®¹, å¦‚æœè¿™æ—¶å€™æˆ‘ä»¬å†æ‰§è¡Œ<code class="language-plaintext highlighter-rouge">terraform apply</code>, terraformä¼šåœ¨å‘½ä»¤è¡Œä¸­è¦æ±‚æˆ‘ä»¬å¡«å†™å¯¹åº”å˜é‡çš„å€¼</p>

<ol>
  <li>
    <p>prompt ä¼ å€¼
å½“ç„¶è¿™æ ·åœ¨æ‰§è¡Œçš„æ—¶å€™ä¼šéœ€è¦æˆ‘ä»¬å¯¹äºæ¯ä¸€ä¸ªpromptéƒ½è¦è¾“å…¥å¯¹åº”å˜é‡çš„å€¼,å®é™…æ“ä½œå¾ˆéº»çƒ¦</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">-var</code> ä¼ å€¼
æˆ‘ä»¬å¯ä»¥åœ¨<code class="language-plaintext highlighter-rouge">terraform apply</code>æ—¶å¢åŠ <code class="language-plaintext highlighter-rouge">-var</code>å¹¶å®šä¹‰å¯¹åº”å˜é‡çš„å€¼, è¿™æ ·å°±ä¸éœ€è¦ä½¿ç”¨promptçš„æ¨¡å¼å¡«å†™å˜é‡äº†</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.tfvars</code> ä¼ å€¼
åœ¨å®é™…ä½¿ç”¨ä¸­, æ›´å¸¸ç”¨çš„æ–¹æ³•å…¶å®æ˜¯ä½¿ç”¨çš„ä¸€ä¸ªå•ç‹¬çš„æ–‡ä»¶æ¥è¿›è¡Œå˜é‡çš„å­˜å‚¨. åœ¨æ‰§è¡Œterraformå‘½ä»¤æ—¶, ä¼šè‡ªåŠ¨æŸ¥æ‰¾ä¸€ä¸ª <code class="language-plaintext highlighter-rouge">terraform.tfvars</code> çš„æ–‡ä»¶, æˆ‘ä»¬å¯ä»¥åœ¨è¿™ä¸ªæ–‡ä»¶ä¸­å®šä¹‰å¯¹åº”å˜é‡çš„åç§°, ä»è€Œå‡å°‘è¾“å…¥å‘½ä»¤è¡Œæ—¶çš„é‡å¤æ“ä½œ</p>
  </li>
</ol>

<p>in terraform.tfvars</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>subnet_prefix = "10.0.0.0/24"
</code></pre></div></div>

<p>æ­¤å¤–, æˆ‘ä»¬å¯ä»¥é‡å‘½åæ­¤å˜é‡æ–‡ä»¶, å¹¶åœ¨<code class="language-plaintext highlighter-rouge">terraform apply</code>æ—¶ä½¿ç”¨ <code class="language-plaintext highlighter-rouge">-var-file</code> ç¡®å®šå…·ä½“éœ€è¦ä½¿ç”¨çš„varæ–‡ä»¶</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;terraform apply -var-file example.tfvars

</code></pre></div></div>

<p>ä½¿ç”¨è¿™ç§æ–¹æ³•å¯ä»¥è®©æˆ‘ä»¬æ›´åŠ æ–¹ä¾¿çš„å¯¹äºä¸åŒé…ç½®çš„é›†ç¾¤è¿›è¡Œä¸åŒå˜é‡å®šä¹‰çš„éƒ¨ç½²</p>]]></content><author><name></name></author><category term="DevOps" /><category term="Tools" /><summary type="html"><![CDATA[General]]></summary></entry><entry><title type="html">Graph Neural Network Notes</title><link href="http://localhost:4000/2022/08/16/Graph-Neural-Network-Notes.html" rel="alternate" type="text/html" title="Graph Neural Network Notes" /><published>2022-08-16T20:59:41+08:00</published><updated>2022-08-16T20:59:41+08:00</updated><id>http://localhost:4000/2022/08/16/Graph-Neural-Network-Notes</id><content type="html" xml:base="http://localhost:4000/2022/08/16/Graph-Neural-Network-Notes.html"><![CDATA[<blockquote>
  <p>Video Link on Youtube: <a href="https://www.youtube.com/watch?v=zCEYiCxrL_0">An Introduction to Graph Neural Networks: Models and Applications</a></p>
</blockquote>

<h1 id="intro">Intro</h1>

<h2 id="distributed-vector-representations">Distributed Vector Representations</h2>

<p><img src="./image-20220531111133794.png" alt="image-20220531111133794" /></p>

<p>From one-hot -&gt; multiply with embedding matrix and get distributed rep.</p>

<p><img src="./image-20220531111258366.png" alt="image-20220531111258366" /></p>

<!-- more -->

<h2 id="graph-notation-basics">Graph Notation Basics</h2>

<ul>
  <li>Nodes/Vertices</li>
  <li>Edges</li>
  <li>$G=(V,E)$</li>
</ul>

<h1 id="graph-neural-network">Graph Neural Network</h1>

<p>By training, each nodeâ€™s vector contains information relative to the whole graph, instead of the initial representation.</p>

<p><img src="./image-20220531111630964.png" alt="image-20220531111630964" /></p>

<ul>
  <li>
    <p>GNNs Synchronous Message Passing (All-to-All)</p>
  </li>
  <li>
    <p>Output:</p>
    <ul>
      <li>Node selection</li>
      <li>Node classification</li>
      <li>Graph classification</li>
    </ul>
  </li>
</ul>

<h2 id="gated-gnns">Gated GNNs</h2>

<p><img src="./image-20220531121358147.png" alt="image-20220531121358147" /></p>

<p>GRU: Gated Recurrent Network</p>

<p><img src="./image-20220531121450912.png" alt="image-20220531121450912" /></p>

<ul>
  <li>permutation invariant -&gt; Sum</li>
</ul>

<h2 id="gcn">GCN</h2>

<p><strong>Trick 1: backwards Edges</strong></p>

<p><img src="./image-20220531121608345.png" alt="image-20220531121608345" /></p>

<ul>
  <li>For each forward edge, add a backward edge</li>
</ul>

<h2 id="graph-notations---adjacency-matrix">Graph Notations - Adjacency Matrix</h2>

<p><img src="./image-20220531121936642.png" alt="image-20220531121936642" /></p>

<h2 id="ggnn-as-matrix-operation">GGNN as Matrix Operation</h2>

<p><img src="./image-20220531122100994.png" alt="image-20220531122100994" /></p>

<h1 id="express-as-code">Express as code</h1>

<ul>
  <li>einsum</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">bd,qd-&gt;bq</span><span class="sh">'</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">abs,be,abq-&gt;cqe</span><span class="sh">'</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./image-20220531122456233.png" alt="image-20220531122456233" /></p>

<p><img src="./image-20220531122502189.png" alt="image-20220531122502189" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">GGNN</span><span class="p">(</span><span class="n">initial_node_states</span><span class="p">,</span> <span class="n">adj</span><span class="p">):</span>
    <span class="n">node_states</span> <span class="o">=</span> <span class="n">initial_node_states</span> <span class="c1">#[N,D]
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_message_types</span><span class="p">):</span>
            <span class="n">message</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">nd,dm-nm</span><span class="sh">'</span><span class="p">,</span> <span class="n">edge_transform</span><span class="p">,</span> <span class="n">node_states</span><span class="p">)</span> <span class="c1"># [N, M]
</span>        <span class="n">received_messages</span> <span class="o">=</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="c1"># (N, M)
</span>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_message_types</span><span class="p">):</span>
            <span class="n">received_messages</span> <span class="o">+=</span> <span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">nm,ml-&gt;lm</span><span class="sh">'</span><span class="p">,</span> <span class="n">message</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">adj</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="n">node_states</span> <span class="o">=</span> <span class="nc">GRU</span><span class="p">(</span><span class="n">node_states</span><span class="p">,</span> <span class="n">received_messages</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">node_states</span>
  
</code></pre></div></div>
<p><strong>Notes</strong>: The adjancency matrix can be very large and sparse</p>

<h1 id="common-arch-of-deep-learning-code">Common Arch of Deep Learning Code</h1>

<p><img src="./image-20220531123935257.png" alt="image-20220531123935257" /></p>]]></content><author><name></name></author><category term="Computer Vision" /><category term="GNN" /><category term="Machine Learning" /><category term="Notes" /><summary type="html"><![CDATA[Video Link on Youtube: An Introduction to Graph Neural Networks: Models and Applications]]></summary></entry><entry><title type="html">Commonly used Activation functions</title><link href="http://localhost:4000/2022/08/01/Activations.html" rel="alternate" type="text/html" title="Commonly used Activation functions" /><published>2022-08-01T23:33:12+08:00</published><updated>2022-08-01T23:33:12+08:00</updated><id>http://localhost:4000/2022/08/01/Activations</id><content type="html" xml:base="http://localhost:4000/2022/08/01/Activations.html"><![CDATA[<h1 id="activation-functions">Activation functions</h1>

<h2 id="why-we-need">Why we need?</h2>

<ul>
  <li>add non-linear factor, solve the problem that linear models cannot represent</li>
  <li>Provide better interpretability to the model</li>
</ul>

<!-- more -->

<h1 id="common-activations">Common activations</h1>

<h2 id="sigmoid">Sigmoid</h2>

\[sig(z) = \frac{1}{e^{-z} + 1}\]

\[sig'(z) = sig(z)(1 - sig(z))\]

<p><img src="./image-20220801155322452.png" alt="image-20220801155322452" /></p>

<ul>
  <li>cons
    <ul>
      <li>left and right all saturated, gradient vanishing</li>
      <li>exponential computation</li>
      <li>not zero-centered, lower convergence speed</li>
    </ul>
  </li>
</ul>

<h2 id="tanh">tanh</h2>

\[tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}\]

<p><img src="./image-20220801155920512.png" alt="image-20220801155920512" /></p>

<p>range from (-1, 1)</p>

<p>adv:</p>

<ul>
  <li>compared with sigmoid
    <ul>
      <li>faster convergence speed, larger slope near 0</li>
      <li>output mean 0</li>
      <li>larger saturated space</li>
    </ul>
  </li>
</ul>

<h2 id="softmax">Softmax</h2>

\[softmax(z) = \frac{e^{z_i}}{\sum_{j=1}^{K}e^{z_j}}\]

<h2 id="relu">relu</h2>

<p><img src="./image-20220801160538133.png" alt="image-20220801160538133" /></p>

<p>dead relu problem: when $ x &lt; 0 $ , ReLU output 0, when backpropagation, the gradient always 0, parameter will never be updated.</p>

<ul>
  <li>adv:
    <ul>
      <li>easy computation</li>
      <li>more similar to bio-inspired mechanism compared to tanh, sigmoid</li>
      <li>does not saturate, solve vanishing gradient</li>
      <li>fast convergence</li>
    </ul>
  </li>
  <li>cons:
    <ul>
      <li>not zero centered</li>
      <li>dead relu problem</li>
    </ul>
  </li>
</ul>

<h2 id="leaky-relu">leaky relu</h2>

\[LeakyReLU(x) = max(0.01x, x)\]

<p>adv:</p>

<ul>
  <li>no dead relu problem</li>
</ul>

<h2 id="elu">elu</h2>

\[ELU(x) = x, x &gt; 0\\
ELU(x) = \alpha(e^x - 1), x \leq 0\]

<ul>
  <li>adv
    <ul>
      <li>mean activation close to 0</li>
      <li>more robust to noise</li>
    </ul>
  </li>
  <li>con
    <ul>
      <li>exponential computation</li>
    </ul>
  </li>
</ul>

<h2 id="maxout">maxout</h2>

<p><img src="maxout1.webp" alt="" /></p>

<p><img src="maxout2.webp" alt="" /></p>

<p>It is a learnable activation function</p>
<ul>
  <li>Activation function in <strong>maxout</strong> network can be any piece-wise linear convex function</li>
  <li>How many pieces depending on how many elements in a group</li>
</ul>]]></content><author><name></name></author><category term="Machine Learning" /><category term="Activation" /><category term="Deep Learning" /><category term="Notes" /><summary type="html"><![CDATA[Activation functions]]></summary></entry><entry><title type="html">Batch Normalization</title><link href="http://localhost:4000/2022/08/01/batch-normalization.html" rel="alternate" type="text/html" title="Batch Normalization" /><published>2022-08-01T20:09:30+08:00</published><updated>2022-08-01T20:09:30+08:00</updated><id>http://localhost:4000/2022/08/01/batch-normalization</id><content type="html" xml:base="http://localhost:4000/2022/08/01/batch-normalization.html"><![CDATA[<h1 id="why">Why</h1>

<p>Model is updated layer-by-layer backward from the output to the input using estimate of error</p>

<p>Because all layers are changed during an update, the update procedure is forever chasing a moving target</p>

<!-- more -->

<p>E.g. the weights of a layer are updated expecting the prior layer outputs values with given distribution, but this distribution will change after the weights of the prior layers are updated</p>

<h2 id="internal-covariate-shift">Internal Covariate Shift</h2>

<p>The the gradient descent proceed, the parameters in each layer would update, making the output distribution change, therefore the tar for the next layer changes, the next layers has to learn the distribution that keeps changing.</p>

<h3 id="influence">Influence</h3>

<ul>
  <li>deep layers have to keep adjusting to learning the input distribution, lower the convergence speed.</li>
  <li>the training tend to go to the saturated space of the activation
    <ul>
      <li>Solution
        <ol>
          <li>Using non saturated activation function</li>
          <li>make the input distribution of the activation in a stable situation, to help it away from the saturated place.</li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h1 id="what">What</h1>

<p>Batch Normalization is proposed as a technique to help coordinate the update of multiple layers in the model</p>

<p>Scaling the output of the layer, by standardizing the activations of each input variable per mini-batch, such as the activations of a node from the previous layer. (Standardization refers to rescaling data to have a mean of zero and standard deviation of one)</p>

<p>Standardizing the activations of the prior layer means that assumptions the subsequent layer makes about the spread and distribution of inputs during the weight update will not change dramatically.</p>

<p>This has the effect of stabilizing and speeding-up the training process of deep neural networks.</p>

<p>Normalizing the inputs to the layers has an effect on the training of the model, dramatcally reducing the number of epochs required. It can also have a regularizing effect. Reducing generalization error much like the use of activation regularization.</p>

<h2 id="equations">Equations</h2>

\[\hat x = \frac{x - mean}{\sqrt{var + eps}}\]

<p>use two extra parameter $\gamma$  and $\beta$ to make recover the expression ability for the data:
\(\hat Z_j = \gamma_j Z_j + \beta_j\)
During testing, we use the average mean and variance from the training procedure:
\(\mu_{test} = E(\mu_{batch})\)</p>

<h2 id="whitening">Whitening</h2>

<p>PCA whitening and ZCA whitening for each layer in every epoch</p>

<h3 id="aim">Aim:</h3>

<ul>
  <li>make the input features have the same mean and standard deviation</li>
  <li>remove relevance between features</li>
</ul>

<h2 id="batch-normalization">Batch Normalization</h2>

<h3 id="why-not-using-whitening">why not using whitening?</h3>

<ul>
  <li>Expensive computation cost</li>
  <li>Whitening process change the distribution of each layer, therefore change the expressiveness of data in each layer. The parameters learned in lower layers would get lost by whitening.</li>
</ul>

<h3 id="idea">Idea</h3>

<p>simplify the computation, normalization for every features, and let every feature has mean 0 and deviation</p>

<p>add the linear transform to make those data revive their expressiveness as much as possible</p>

<h1 id="batch-renormalization">Batch Renormalization</h1>

<p>For small mini-batches that do not contain a representative distribution of examples from the training dataset, the difference in the standarized inputs between training and inference can result in noticeable difference in performance.</p>

<p>Batch Renormalization makes the estimate of the variable mean and standard deviation more stable across mini-batches.</p>

<h1 id="practice">Practice</h1>

<p>In practice, it is common to allow the layer to learn a new mean and standard deviation, beta and gamma, that wallow the automatic scaling and shifting of the standarized layer inputs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>


<span class="sh">'''</span><span class="s">
X.shape = [b, c, h, w] for 2d
X.shape = [b, d] for 1d
</span><span class="sh">'''</span>
<span class="k">def</span> <span class="nf">batch_norm</span><span class="p">(</span><span class="n">is_training</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">moving_mean</span><span class="p">,</span> <span class="n">moving_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">):</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="n">is_training</span><span class="p">:</span>
      	<span class="n">X_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">moving_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">moving_var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      	<span class="n">feature_shape</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">feature_shae</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">feature_shape</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
         <span class="c1"># for norm1d
</span>        		<span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
          	<span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
            
        <span class="k">else</span><span class="p">:</span>
          	<span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">keepdim</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
            <span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdim</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">X_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        
        <span class="c1"># momentum smoothing
</span>        <span class="n">moving_mean</span> <span class="o">=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">moving_mean</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">mean</span>
        <span class="n">moving_var</span> <span class="o">=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">moving_var</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">var</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">X_h</span> <span class="o">+</span> <span class="n">beta</span>
  	<span class="k">return</span> <span class="n">Y</span><span class="p">,</span> <span class="n">moving_mean</span><span class="p">,</span> <span class="n">moving_var</span>

<span class="k">class</span> <span class="nc">_BatchNorm</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="n">num_dims</span><span class="p">,</span> <span class="n">momentum</span><span class="p">):</span>
    		<span class="nf">super</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">num_dims</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_dims</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
          	<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_dims</span><span class="p">)</span>
       	<span class="k">else</span><span class="p">:</span>
          	<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">moving_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">moving_var</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
      	<span class="n">Y</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">moving_mean</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">moving_var</span> <span class="o">=</span> <span class="nf">batch_norm</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">is_training</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">gamma</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">moving_mean</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">moving_var</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">momentum</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Y</span>
<span class="k">class</span> <span class="nc">BatchNorm1d</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">):</span>
  	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">nums_features</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>

</code></pre></div></div>

<h1 id="comparison">Comparison</h1>

<h2 id="with-layer-normalization">With layer normalization</h2>

<ul>
  <li>
    <p>BN work for a batch of training examples, where LN work for single sample.</p>
  </li>
  <li>BN standardize across features for samples, where LN standardize for all features in the single sample</li>
  <li>LN better used in NLP</li>
</ul>]]></content><author><name></name></author><category term="Machine Learning" /><category term="Batch Normalization" /><summary type="html"><![CDATA[Why]]></summary></entry><entry><title type="html">Use T-SNE for a better visualization</title><link href="http://localhost:4000/2022/07/11/TSNE-notes.html" rel="alternate" type="text/html" title="Use T-SNE for a better visualization" /><published>2022-07-11T18:31:11+08:00</published><updated>2022-07-11T18:31:11+08:00</updated><id>http://localhost:4000/2022/07/11/TSNE-notes</id><content type="html" xml:base="http://localhost:4000/2022/07/11/TSNE-notes.html"><![CDATA[<h1 id="definition">Definition</h1>

<p>t-distributed stochastic neighbor embedding (t-SNE) is a methods to visualise high dimension data by transforming each data into a two or three dimensional map. It models in a way that similar objects are modeled by nearby points and dissimilar objects are modelled by distant points with high probability.</p>

<!-- more -->

<h1 id="stages">Stages</h1>

<ol>
  <li>constructs a probability distribution over pairs of high-dimensional objects in such a way that similar objects are assigned a higher probability while dissimilar points are assigned a lower probability.</li>
  <li>t-SNE defines a similar probability distribution over the points in the low-dimensional map, and it minimise the KL divergence between the two distributions with respect to the locations of the points in the map.</li>
</ol>

<h1 id="demo-code">Demo Code</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># simple example
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">X_embedded</span> <span class="o">=</span> <span class="nc">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="sh">'</span><span class="s">auto</span><span class="sh">'</span><span class="p">,</span><span class="n">init</span><span class="o">=</span><span class="sh">'</span><span class="s">random</span><span class="sh">'</span><span class="p">).</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_embedded</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<h2 id="parameters-for-sklearnmanifoldtsne">Parameters for sklearn.manifold.TSNE</h2>

<blockquote>
  <p>Source: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"><code class="language-plaintext highlighter-rouge">sklearn.manifold</code>.TSNE</a></p>
</blockquote>

<p>Parameters:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>n_components: int, default=2
Dimension of the embedded space.

perplexity: float, default=30.0
The perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. Different values can result in significantly different results.

early_exaggeration: float, default=12.0
Controls how tight natural clusters in the original space are in the embedded space and how much space will be between them. For larger values, the space between natural clusters will be larger in the embedded space. Again, the choice of this parameter is not very critical. If the cost function increases during initial optimization, the early exaggeration factor or the learning rate might be too high.

learning_rate: float or â€˜autoâ€™, default=200.0
The learning rate for t-SNE is usually in the range [10.0, 1000.0]. If the learning rate is too high, the data may look like a â€˜ballâ€™ with any point approximately equidistant from its nearest neighbours. If the learning rate is too low, most points may look compressed in a dense cloud with few outliers. If the cost function gets stuck in a bad local minimum increasing the learning rate may help. Note that many other t-SNE implementations (bhtsne, FIt-SNE, openTSNE, etc.) use a definition of learning_rate that is 4 times smaller than ours. So our learning_rate=200 corresponds to learning_rate=800 in those other implementations. The â€˜autoâ€™ option sets the learning_rate to max(N / early_exaggeration / 4, 50) where N is the sample size, following [4] and [5]. This will become default in 1.2.

n_iter: int, default=1000
Maximum number of iterations for the optimization. Should be at least 250.

n_iter_without_progress: int, default=300
Maximum number of iterations without progress before we abort the optimization, used after 250 initial iterations with early exaggeration. Note that progress is only checked every 50 iterations so this value is rounded to the next multiple of 50.

New in version 0.17: parameter n_iter_without_progress to control stopping criteria.

min_grad_norm: float, default=1e-7
If the gradient norm is below this threshold, the optimization will be stopped.

metricstr or callable, default=â€™euclideanâ€™
The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by scipy.spatial.distance.pdist for its metric parameter, or a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS. If metric is â€œprecomputedâ€, X is assumed to be a distance matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them. The default is â€œeuclideanâ€ which is interpreted as squared euclidean distance.

metric_params: dict, default=None
Additional keyword arguments for the metric function.

New in version 1.1.

init: {â€˜randomâ€™, â€˜pcaâ€™} or ndarray of shape (n_samples, n_components), default=â€™randomâ€™
Initialization of embedding. Possible options are â€˜randomâ€™, â€˜pcaâ€™, and a numpy array of shape (n_samples, n_components). PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization. init='pca' will become default in 1.2.

verbose: int, default=0
Verbosity level.

random_state: int, RandomState instance or None, default=None
Determines the random number generator. Pass an int for reproducible results across multiple function calls. Note that different initializations might result in different local minima of the cost function. See Glossary.

method: str, default=â€™barnes_hutâ€™
By default the gradient calculation algorithm uses Barnes-Hut approximation running in O(NlogN) time. method=â€™exactâ€™ will run on the slower, but exact, algorithm in O(N^2) time. The exact algorithm should be used when nearest-neighbor errors need to be better than 3%. However, the exact method cannot scale to millions of examples.

New in version 0.17: Approximate optimization method via the Barnes-Hut.

angle: float, default=0.5
Only used if method=â€™barnes_hutâ€™ This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. â€˜angleâ€™ is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below â€˜angleâ€™ then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.

n_jobs: int, default=None
The number of parallel jobs to run for neighbors search. This parameter has no impact when metric="precomputed" or (metric="euclidean" and method="exact"). None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

New in version 0.22.

square_distances: True, default=â€™deprecatedâ€™
This parameter has no effect since distance values are always squared since 1.1.
</code></pre></div></div>

<p>Attributes:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>embedding_: array-like of shape (n_samples, n_components)
Stores the embedding vectors.

kl_divergence_: float
Kullback-Leibler divergence after optimization.

n_features_in_: int
Number of features seen during fit.

New in version 0.24.

feature_names_in_: ndarray of shape (n_features_in_,)
Names of features seen during fit. Defined only when X has feature names that are all strings.

New in version 1.0.

n_iter_: int
Number of iterations run.
</code></pre></div></div>

<p>Methods:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[,</span><span class="n">y</span><span class="p">])</span> <span class="c1"># fit X into a embedded space
</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[,</span><span class="n">y</span><span class="p">])</span> <span class="c1"># fit X into an embedded space and return that transformed output
</span><span class="nf">get_params</span><span class="p">([</span><span class="n">deep</span><span class="p">])</span> <span class="c1"># Get parameters for this estimator
</span><span class="nf">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span> <span class="c1"># set the parameters of this estimator
</span></code></pre></div></div>

<h1 id="algorithm-details">Algorithm details</h1>

<h1 id="compare-to-other-dimensionality-reduction-methods">Compare to other dimensionality reduction methods</h1>

<h2 id="pca">PCA</h2>

<p>dense data</p>

<h2 id="truncated-svd">Truncated SVD</h2>

<p>sparse data</p>]]></content><author><name></name></author><category term="t-SNE" /><category term="Machine Learning" /><category term="Visualization" /><category term="Notes" /><summary type="html"><![CDATA[Definition]]></summary></entry><entry><title type="html">RandLA Network Analysis</title><link href="http://localhost:4000/2022/06/23/RandLA-reading-Notes.html" rel="alternate" type="text/html" title="RandLA Network Analysis" /><published>2022-06-23T21:44:52+08:00</published><updated>2022-06-23T21:44:52+08:00</updated><id>http://localhost:4000/2022/06/23/RandLA-reading-Notes</id><content type="html" xml:base="http://localhost:4000/2022/06/23/RandLA-reading-Notes.html"><![CDATA[<blockquote>
  <p>Abstract: Notes for Architecture and building blocks for the RandLA which is implemented in the experiment</p>
</blockquote>

<!-- more -->

<h1 id="building-blocks">Building Blocks</h1>
<ol>
  <li>
    <p>Local feature aggregation
  1.Local Spatial encoding (LocSE)
       <img src="./image-20220623135520057.png" alt="image-20220623135520057" />
       â€“&gt; 3+d: xyz position + other per-point features (e.g. RGB or other intermediate learned features)</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Objective
   â€‹	**Encode xyz coordinates of all neighbouring points for each point to aware of relative spatial locations.**
   Steps:
    1. Finding neighbouring points
          for $ith$ point, gather neighbouring points by $KNN$ for efficiency, based on Euclidean distances.
   2. Relative Point Position encoding
        concatenate the xyz positions of ith points, neighbour k of ith points, element-wise subtraction, Euclidean distance of two points
   3. Point Feature Augmentation
        Concatenate relative point position with corresponding point features f.
</code></pre></div>    </div>
  </li>
</ol>

<p>2.Attentive pooling
     Objective
     â€‹	Aggregate the set of neighbouring point features f, use attention mechanism to automatically learn important local features.
     Steps: 
          1.Computing Attention Scores
          2.Weighted Summation
          3.dilated residual block</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> â€‹    
</code></pre></div></div>]]></content><author><name></name></author><category term="Deep Learning" /><category term="Point Clouds" /><category term="Notes" /><summary type="html"><![CDATA[Abstract: Notes for Architecture and building blocks for the RandLA which is implemented in the experiment]]></summary></entry><entry><title type="html">Point Cloud Visualization Utils</title><link href="http://localhost:4000/2022/06/22/point-cloud-visualization-utils.html" rel="alternate" type="text/html" title="Point Cloud Visualization Utils" /><published>2022-06-22T19:23:16+08:00</published><updated>2022-06-22T19:23:16+08:00</updated><id>http://localhost:4000/2022/06/22/point-cloud-visualization-utils</id><content type="html" xml:base="http://localhost:4000/2022/06/22/point-cloud-visualization-utils.html"><![CDATA[<ol>
  <li>Codes for visualizing point clouds (without labels)</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyvista</span> <span class="k">as</span> <span class="n">pv</span>
<span class="n">pv</span><span class="p">.</span><span class="nf">start_xvfb</span><span class="p">()</span> <span class="c1"># start a session
</span>
<span class="n">point_clouds</span> <span class="o">=</span> <span class="nc">ShapeNet</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">../dataset/shapenet</span><span class="sh">'</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="sh">'</span><span class="s">trainval</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pcd</span> <span class="o">=</span> <span class="n">point_clouds</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">pos</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> <span class="c1"># pick a specific point cloud data from the dataset
</span><span class="n">points</span> <span class="o">=</span> <span class="n">pv</span><span class="p">.</span><span class="nc">PolyData</span><span class="p">(</span><span class="n">pcd</span><span class="p">)</span> <span class="c1"># plot the dataset
</span><span class="n">points</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">jupyter_backend</span><span class="o">=</span><span class="sh">'</span><span class="s">panel</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># set the visualization interactive
</span>
</code></pre></div></div>

<!-- more -->]]></content><author><name></name></author><category term="Memo" /><summary type="html"><![CDATA[Codes for visualizing point clouds (without labels)]]></summary></entry></feed>